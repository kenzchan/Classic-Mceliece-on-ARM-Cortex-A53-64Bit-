/*
  This file is for matrix transposition
*/

#ifndef TRANSPOSE_H
#define TRANSPOSE_H

#include "vec128.h"

#include <stdint.h>

//#define transpose_64x128_sp_asm CRYPTO_NAMESPACE(transpose_64x128_sp_asm)

/*
static inline void transpose_64x64(uint64_t * in)
{
	int i, j, s, d;

	//uint64_t * out = in;
	uint64_t x, y;
	uint64_t masks[6][2] = {
	                        {0x5555555555555555, 0xAAAAAAAAAAAAAAAA},
	                        {0x3333333333333333, 0xCCCCCCCCCCCCCCCC},
	                        {0x0F0F0F0F0F0F0F0F, 0xF0F0F0F0F0F0F0F0},
	                        {0x00FF00FF00FF00FF, 0xFF00FF00FF00FF00},
	                        {0x0000FFFF0000FFFF, 0xFFFF0000FFFF0000},
	                        {0x00000000FFFFFFFF, 0xFFFFFFFF00000000}
	                       };

	//for (i = 0; i < 64; i++)
	//	out[i] = in[i];

	for (d = 5; d >= 0; d--)
	{
		s = 1 << d;

		for (i = 0; i < 64; i += s*2)
		for (j = i; j < i+s; j++)
		{
			x = (in[j] & masks[d][0]) | ((in[j+s] & masks[d][0]) << s);
			y = ((in[j] & masks[d][1]) >> s) | (in[j+s] & masks[d][1]);

			in[j+0] = x;
			in[j+s] = y;
		}
	}
	//in = out;
}
*/


/*
static inline void transpose_64x64(uint64_t * in)
{
	int i, j, s, d;

	uint64_t x, y;
	uint64_t masks[3][2] = {
	                        {0x5555555555555555, 0xAAAAAAAAAAAAAAAA},
	                        {0x3333333333333333, 0xCCCCCCCCCCCCCCCC},
	                        {0x0F0F0F0F0F0F0F0F, 0xF0F0F0F0F0F0F0F0},
	                        //{0x00FF00FF00FF00FF, 0xFF00FF00FF00FF00},
	                        //{0x0000FFFF0000FFFF, 0xFFFF0000FFFF0000},
	                        //{0x00000000FFFFFFFF, 0xFFFFFFFF00000000}
	                       };
	// First round
	s = 0b100000;
	//uint32x2x2_t tmp_32x2[32];

	for (i = 0; i < 64; i += s*2)
	for (j = i; j < i+s; j++)
	{
		uint32x2x2_t tmp_1 = vtrn_u32(vreinterpret_u32_u64(in[j]), vreinterpret_u32_u64(in[j+s]));

		in[j+0] = vreinterpret_u64_u32(tmp_1.val[0]);
		in[j+s] = vreinterpret_u64_u32(tmp_1.val[1]);
	}

	// Second round
	s >>= 1;
	for (i = 0; i < 64; i += s*2)
	for (j = i; j < i+s; j++)
	{
		uint16x4x2_t tmp_2 = vtrn_u16(vreinterpret_u16_u64(in[j]), vreinterpret_u16_u64(in[j+s]));

		in[j+0] = vreinterpret_u64_u16(tmp_2.val[0]);
		in[j+s] = vreinterpret_u64_u16(tmp_2.val[1]);
	}

	// Third round
	s >>= 1;
	for (i = 0; i < 64; i += s*2)
	for (j = i; j < i+s; j++)
	{
		uint8x8x2_t tmp_3 = vtrn_u8(vreinterpret_u8_u64(in[j]), vreinterpret_u8_u64(in[j+s]));

		in[j+0] = vreinterpret_u64_u8(tmp_3.val[0]);
		in[j+s] = vreinterpret_u64_u8(tmp_3.val[1]);
	}

	for (d = 2; d >= 0; d--)
	{
		s = 1 << d;

		for (i = 0; i < 64; i += s*2)
		for (j = i; j < i+s; j++)
		{
			x = (in[j] & masks[d][0]) | ((in[j+s] & masks[d][0]) << s);
			y = ((in[j] & masks[d][1]) >> s) | (in[j+s] & masks[d][1]);

			in[j+0] = x;
			in[j+s] = y;
		}
	}
}
*/


/*
static inline void transpose_64x64(uint64_t *in)
{
	uint64_t tmp[64];

	for (int k = 0; k< 64; k++){
		tmp[k] = in[k];
	}

	for (int i = 0; i < 64; i++){
		uint64_t tmp_val;
		tmp_val &= 0;

		for (int j = 0; j < 64; j++){
			tmp_val |= (((tmp[j]>>i) & 1)<<j);
		}
		in[i] = tmp_val;
	}

}
*/

static inline void transpose_64x64(uint64_t * in)
{
	int i, j, s, d;

	uint64_t x, y;
	uint64_t masks[3][2] = {
	                        {0x5555555555555555, 0xAAAAAAAAAAAAAAAA},
	                        {0x3333333333333333, 0xCCCCCCCCCCCCCCCC},
	                        {0x0F0F0F0F0F0F0F0F, 0xF0F0F0F0F0F0F0F0},
	                       };
	// First round
	uint32x2x2_t tmp_32[32];
	uint16x4x2_t tmp_16[32];

	//for (i = 0; i < 64; i += s*2)
	for (i = 0; i < 64; i++)
	{
		tmp_32[i] = vtrn_u32(vreinterpret_u32_u64(in[i]), vreinterpret_u32_u64(in[i+64]));
	}

	// Second round
	for (i = 0; i < 32; i++)// s = 16
	{
		tmp_16[i] = vtrn_u16(vreinterpret_u16_u32(tmp_32[i].val[0]), vreinterpret_u16_u32(tmp_32[i+32].val[0]));
		tmp_16[i+32] = vtrn_u16(vreinterpret_u16_u32(tmp_32[i].val[1]), vreinterpret_u16_u32(tmp_32[i+32].val[1]));
	}

	// Third round
	for (i = 0; i < 8; i++)// s = 8
	{
		uint8x8x2_t tmp_8_0 = vtrn_u8(vreinterpret_u8_u16(tmp_16[i].val[0]), vreinterpret_u8_u16(tmp_16[i+8].val[0]));
		uint8x8x2_t tmp_8_1 = vtrn_u8(vreinterpret_u8_u16(tmp_16[i].val[1]), vreinterpret_u8_u16(tmp_16[i+8].val[1]));

		uint8x8x2_t tmp_8_2 = vtrn_u8(vreinterpret_u8_u16(tmp_16[16+i].val[0]), vreinterpret_u8_u16(tmp_16[24+i].val[0]));
		uint8x8x2_t tmp_8_3 = vtrn_u8(vreinterpret_u8_u16(tmp_16[16+i].val[1]), vreinterpret_u8_u16(tmp_16[24+i].val[1]));


		in[i+0] = vreinterpret_u64_u8(tmp_8_0.val[0]);
		in[i+8] = vreinterpret_u64_u8(tmp_8_0.val[1]);

		in[16+i] = vreinterpret_u64_u8(tmp_8_1.val[0]);
		in[24+i] = vreinterpret_u64_u8(tmp_8_1.val[1]);

		in[32+i] = vreinterpret_u64_u8(tmp_8_2.val[0]);
		in[40+i] = vreinterpret_u64_u8(tmp_8_2.val[1]);

		in[48+i] = vreinterpret_u64_u8(tmp_8_3.val[0]);
		in[56+i] = vreinterpret_u64_u8(tmp_8_3.val[1]);
	}
	

	for (d = 2; d >= 0; d--)
	{
		s = 1 << d;

		for (i = 0; i < 64; i += s*2)
		for (j = i; j < i+s; j++)
		{
			x = (in[j] & masks[d][0]) | ((in[j+s] & masks[d][0]) << s);
			y = ((in[j] & masks[d][1]) >> s) | (in[j+s] & masks[d][1]);

			in[j+0] = x;
			in[j+s] = y;
		}
	}
}

/*
extern void transpose_64x128_sp_asm(vec128 *);

static inline void transpose_64x128_sp(vec128 *in)
{
	transpose_64x128_sp_asm(in);
}
*/
static inline void transpose_64x128_sp(vec128 * in)
{
	uint64_t tmp1[64];
	uint64_t tmp2[64];

	//uint64_t masks[2] = { 0x00000000FFFFFFFF, 0xFFFFFFFF00000000 };

	for (int i = 0; i < 64; i++){
		tmp1[i] = in[i][0]; //& masks[0];
		tmp2[i] = in[i][1]; //& masks[1];
	}

	transpose_64x64(tmp1);
	transpose_64x64(tmp2);

	for (int c = 0; c < 64; c++){
		in[c][0] = tmp1[c];
		in[c][1] = tmp2[c];
	}

}

/*
static inline void transpose_64x128_sp(vec128 *in)
{
	vec128 tmp[128];

	for (int i = 0; i < 128; i++){
		vec128 tmp_val;
		tmp_val &= 0;
		for (int j = 0; j < 64; j++){
			tmp_val <<= 1;
			tmp_val |= (in[j]>>(64-j-1))&1;			
		}
		tmp[i] = (tmp_val<<63);
		tmp[i] >>= 63;

	}

	in = tmp;
}
*/


#endif
















